{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a78fa28e-5214-482c-b7a9-8ba1bad5b0e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##DAY 3: GOLD LAYER & ML READY FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdc764ab-7c92-4925-bcaa-bb3ff5736c08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83C\uDFAF part 3: GOLD LAYER & ML FEATURE ENGINEERING\n======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\uD83C\uDFAF part 3: GOLD LAYER & ML FEATURE ENGINEERING\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e7eac7c-154c-4b4d-841e-2f348c5038b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### SET CATALOG & CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea9a81d7-2fe3-4eaa-b83e-07ef639a7285",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n0️⃣ SETTING UP GOLD LAYER\n✅ Gold and ML schemas ready\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n0️⃣ SETTING UP GOLD LAYER\")\n",
    "\n",
    "spark.sql(\"USE CATALOG brazil_project\")\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS gold\")\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS ml\")\n",
    "\n",
    "print(\"✅ Gold and ML schemas ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6f0eb1e-51fb-4a0d-8df6-bbe534c6b954",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###1: ML-READY CUSTOMER FEATURES (GOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad8679fe-5a4f-4971-914c-0f302eacac20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n1️⃣ CREATING ML-READY CUSTOMER FEATURES (GOLD)\n✅ ML Customer Features created: 98,666 customers\n   Features: 25+ engineered features for ML\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1️⃣ CREATING ML-READY CUSTOMER FEATURES (GOLD)\")\n",
    "\n",
    "# Create comprehensive ML features\n",
    "ml_customer_features = \"\"\"\n",
    "WITH customer_base AS (\n",
    "    SELECT \n",
    "        c.customer_id,\n",
    "        c.customer_city,\n",
    "        c.customer_state,\n",
    "        \n",
    "        -- Basic metrics\n",
    "        c.total_orders,\n",
    "        c.total_spent,\n",
    "        c.avg_order_value,\n",
    "        c.recency_score,\n",
    "        c.frequency_score, \n",
    "        c.monetary_score,\n",
    "        c.churned_90d,\n",
    "        \n",
    "        -- Time-based features\n",
    "        c.first_order_date,\n",
    "        c.last_order_date,\n",
    "        DATEDIFF(c.last_order_date, c.first_order_date) as customer_tenure_days,\n",
    "        DATEDIFF(CURRENT_DATE(), c.last_order_date) as days_since_last_purchase,\n",
    "        \n",
    "        -- RFM composite score\n",
    "        (c.recency_score + c.frequency_score + c.monetary_score) as rfm_total_score\n",
    "        \n",
    "    FROM silver.customer_360_simple c\n",
    "    WHERE c.total_orders > 0  -- Only customers with at least one order\n",
    "),\n",
    "customer_behavior AS (\n",
    "    SELECT \n",
    "        o.customer_id,\n",
    "        \n",
    "        -- Product diversity\n",
    "        COUNT(DISTINCT p.product_category_name) as unique_categories_purchased,\n",
    "        \n",
    "        -- Payment behavior\n",
    "        COUNT(DISTINCT op.payment_type) as unique_payment_methods,\n",
    "        AVG(op.payment_installments) as avg_installments,\n",
    "        \n",
    "        -- Review behavior\n",
    "        COUNT(DISTINCT rev.review_id) as total_reviews,\n",
    "        AVG(rev.review_score) as avg_review_score,\n",
    "        \n",
    "        -- Delivery experience\n",
    "        AVG(DATEDIFF(o.order_delivered_customer_date, o.order_purchase_timestamp)) as avg_delivery_days,\n",
    "        \n",
    "        -- Order status analysis\n",
    "        SUM(CASE WHEN o.order_status = 'delivered' THEN 1 ELSE 0 END) as delivered_orders,\n",
    "        SUM(CASE WHEN o.order_status = 'canceled' THEN 1 ELSE 0 END) as canceled_orders,\n",
    "        SUM(CASE WHEN o.order_status = 'unavailable' THEN 1 ELSE 0 END) as unavailable_orders\n",
    "        \n",
    "    FROM bronze.orders o\n",
    "    LEFT JOIN bronze.order_items oi ON o.order_id = oi.order_id\n",
    "    LEFT JOIN bronze.products p ON oi.product_id = p.product_id\n",
    "    LEFT JOIN bronze.order_payments op ON o.order_id = op.order_id\n",
    "    LEFT JOIN bronze.order_reviews rev ON o.order_id = rev.order_id\n",
    "    GROUP BY o.customer_id\n",
    "),\n",
    "customer_geography AS (\n",
    "    SELECT \n",
    "        customer_state,\n",
    "        COUNT(*) as state_total_customers,\n",
    "        AVG(total_spent) as state_avg_spent\n",
    "    FROM silver.customer_360_simple\n",
    "    WHERE total_spent > 0\n",
    "    GROUP BY customer_state\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    cb.*,\n",
    "    \n",
    "    -- Behavioral features\n",
    "    COALESCE(cbh.unique_categories_purchased, 0) as unique_categories_purchased,\n",
    "    COALESCE(cbh.unique_payment_methods, 0) as unique_payment_methods,\n",
    "    COALESCE(cbh.avg_installments, 0) as avg_installments,\n",
    "    COALESCE(cbh.total_reviews, 0) as total_reviews,\n",
    "    COALESCE(cbh.avg_review_score, 0) as avg_review_score,\n",
    "    COALESCE(cbh.avg_delivery_days, 0) as avg_delivery_days,\n",
    "    COALESCE(cbh.delivered_orders, 0) as delivered_orders,\n",
    "    COALESCE(cbh.canceled_orders, 0) as canceled_orders,\n",
    "    COALESCE(cbh.unavailable_orders, 0) as unavailable_orders,\n",
    "    \n",
    "    -- Geographic context\n",
    "    COALESCE(cg.state_total_customers, 0) as state_total_customers,\n",
    "    COALESCE(cg.state_avg_spent, 0) as state_avg_spent,\n",
    "    \n",
    "    -- Derived features\n",
    "    CASE \n",
    "        WHEN cb.customer_tenure_days > 180 THEN 'Established'\n",
    "        WHEN cb.customer_tenure_days > 90 THEN 'Growing'\n",
    "        WHEN cb.customer_tenure_days > 30 THEN 'New'\n",
    "        ELSE 'Very New'\n",
    "    END as customer_segment,\n",
    "    \n",
    "    CASE \n",
    "        WHEN cb.avg_order_value > 200 THEN 'High Value'\n",
    "        WHEN cb.avg_order_value > 100 THEN 'Medium Value'\n",
    "        WHEN cb.avg_order_value > 50 THEN 'Low Value'\n",
    "        ELSE 'Very Low Value'\n",
    "    END as value_segment,\n",
    "    \n",
    "    -- Interaction features\n",
    "    cb.total_orders * cb.avg_order_value as estimated_lifetime_value,\n",
    "    \n",
    "    -- Target variable for ML (next 30-day churn)\n",
    "    CASE \n",
    "        WHEN cb.days_since_last_purchase > 60 AND cb.days_since_last_purchase <= 90 THEN 1\n",
    "        ELSE 0\n",
    "    END as churn_next_30d  -- ML TARGET\n",
    "    \n",
    "FROM customer_base cb\n",
    "LEFT JOIN customer_behavior cbh ON cb.customer_id = cbh.customer_id\n",
    "LEFT JOIN customer_geography cg ON cb.customer_state = cg.customer_state\n",
    "\"\"\"\n",
    "\n",
    "# Execute and save to Gold\n",
    "ml_customer_df = spark.sql(ml_customer_features)\n",
    "ml_customer_df.write.mode(\"overwrite\").saveAsTable(\"brazil_project.gold.ml_customer_features\")\n",
    "\n",
    "print(f\"✅ ML Customer Features created: {ml_customer_df.count():,} customers\")\n",
    "print(\"   Features: 25+ engineered features for ML\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8501f211-0905-4045-8d65-a3a41f00b4ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###2: PRODUCT ML FEATURES (GOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f441896-d540-43c7-b180-ed568bb3dcf8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n2️⃣ CREATING PRODUCT ML FEATURES\n✅ ML Product Features created: 32,951 products\n   Features: 20+ features for product recommendation ML\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2️⃣ CREATING PRODUCT ML FEATURES\")\n",
    "\n",
    "product_ml_features = \"\"\"\n",
    "WITH product_sales AS (\n",
    "    SELECT \n",
    "        p.product_id,\n",
    "        p.product_category_name,\n",
    "        \n",
    "        -- Sales metrics\n",
    "        COUNT(DISTINCT oi.order_id) as total_orders,\n",
    "        COUNT(oi.order_item_id) as total_items_sold,\n",
    "        SUM(oi.price) as total_revenue,\n",
    "        AVG(oi.price) as avg_price,\n",
    "        STDDEV(oi.price) as price_stddev,\n",
    "        \n",
    "        -- Temporal metrics\n",
    "        MIN(o.order_purchase_timestamp) as first_sale_date,\n",
    "        MAX(o.order_purchase_timestamp) as last_sale_date,\n",
    "        \n",
    "        -- Customer engagement\n",
    "        COUNT(DISTINCT o.customer_id) as unique_customers,\n",
    "        COUNT(DISTINCT oi.seller_id) as unique_sellers\n",
    "        \n",
    "    FROM bronze.products p\n",
    "    LEFT JOIN bronze.order_items oi ON p.product_id = oi.product_id\n",
    "    LEFT JOIN bronze.orders o ON oi.order_id = o.order_id\n",
    "    GROUP BY p.product_id, p.product_category_name\n",
    "),\n",
    "product_reviews_agg AS (\n",
    "    SELECT \n",
    "        p.product_id,\n",
    "        COUNT(rev.review_id) as total_reviews,\n",
    "        AVG(rev.review_score) as avg_review_score,\n",
    "        STDDEV(rev.review_score) as review_score_stddev,\n",
    "        SUM(CASE WHEN rev.review_score = 5 THEN 1 ELSE 0 END) as five_star_reviews,\n",
    "        SUM(CASE WHEN rev.review_score <= 2 THEN 1 ELSE 0 END) as poor_reviews\n",
    "        \n",
    "    FROM bronze.products p\n",
    "    LEFT JOIN bronze.order_items oi ON p.product_id = oi.product_id\n",
    "    LEFT JOIN bronze.order_reviews rev ON oi.order_id = rev.order_id\n",
    "    GROUP BY p.product_id\n",
    "),\n",
    "product_category_stats AS (\n",
    "    SELECT \n",
    "        product_category_name,\n",
    "        COUNT(DISTINCT product_id) as category_total_products,\n",
    "        AVG(total_items_sold) as category_avg_items_sold\n",
    "    FROM product_sales\n",
    "    WHERE product_category_name IS NOT NULL\n",
    "    GROUP BY product_category_name\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    ps.*,\n",
    "    \n",
    "    -- Review metrics\n",
    "    COALESCE(pr.total_reviews, 0) as total_reviews,\n",
    "    COALESCE(pr.avg_review_score, 0) as avg_review_score,\n",
    "    COALESCE(pr.review_score_stddev, 0) as review_score_stddev,\n",
    "    COALESCE(pr.five_star_reviews, 0) as five_star_reviews,\n",
    "    COALESCE(pr.poor_reviews, 0) as poor_reviews,\n",
    "    \n",
    "    -- Category context\n",
    "    COALESCE(pcs.category_total_products, 0) as category_total_products,\n",
    "    COALESCE(pcs.category_avg_items_sold, 0) as category_avg_items_sold,\n",
    "    \n",
    "    -- Derived features\n",
    "    CASE \n",
    "        WHEN ps.total_items_sold = 0 THEN 0\n",
    "        ELSE ps.total_revenue / ps.total_items_sold\n",
    "    END as revenue_per_item,\n",
    "    \n",
    "    CASE \n",
    "        WHEN ps.total_items_sold = 0 THEN 0\n",
    "        ELSE ps.unique_customers * 1.0 / ps.total_items_sold\n",
    "    END as customer_penetration_rate,\n",
    "    \n",
    "    DATEDIFF(CURRENT_DATE(), ps.last_sale_date) as days_since_last_sale,\n",
    "    \n",
    "    -- Sales velocity\n",
    "    CASE \n",
    "        WHEN DATEDIFF(ps.last_sale_date, ps.first_sale_date) = 0 THEN ps.total_items_sold\n",
    "        ELSE ps.total_items_sold * 1.0 / DATEDIFF(ps.last_sale_date, ps.first_sale_date)\n",
    "    END as daily_sales_rate,\n",
    "    \n",
    "    -- Product success score (composite)\n",
    "    (COALESCE(ps.total_items_sold, 0) * 0.3 +\n",
    "     COALESCE(pr.avg_review_score, 0) * 0.4 +\n",
    "     COALESCE(ps.unique_customers, 0) * 0.3) as product_success_score,\n",
    "    \n",
    "    -- Target for ML: High demand product\n",
    "    CASE \n",
    "        WHEN ps.total_items_sold > 50 AND pr.avg_review_score > 4.0 THEN 1\n",
    "        ELSE 0\n",
    "    END as high_demand_product\n",
    "    \n",
    "FROM product_sales ps\n",
    "LEFT JOIN product_reviews_agg pr ON ps.product_id = pr.product_id\n",
    "LEFT JOIN product_category_stats pcs ON ps.product_category_name = pcs.product_category_name\n",
    "\"\"\"\n",
    "# Execute and save\n",
    "product_ml_df = spark.sql(product_ml_features)\n",
    "product_ml_df.write.mode(\"overwrite\").saveAsTable(\"brazil_project.gold.ml_product_features\")\n",
    "\n",
    "print(f\"✅ ML Product Features created: {product_ml_df.count():,} products\")\n",
    "print(\"   Features: 20+ features for product recommendation ML\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88663121-755a-4f97-a24e-016e6e01bd20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##3: TIME-SERIES FEATURES (GOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60940410-e8d5-4d98-9ca6-2e95cdf01189",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n3️⃣ CREATING TIME-SERIES FEATURES\n✅ Time-Series Features created: 616 days\n   Features: Daily metrics with rolling averages for forecasting\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n3️⃣ CREATING TIME-SERIES FEATURES\")\n",
    "\n",
    "time_series_features = \"\"\"\n",
    "SELECT \n",
    "    DATE(o.order_purchase_timestamp) as order_date,\n",
    "    \n",
    "    -- Daily metrics\n",
    "    COUNT(DISTINCT o.order_id) as daily_orders,\n",
    "    COUNT(DISTINCT o.customer_id) as daily_customers,\n",
    "    COUNT(DISTINCT oi.seller_id) as daily_sellers,\n",
    "    SUM(oi.price) as daily_revenue,\n",
    "    AVG(oi.price) as avg_order_value,\n",
    "    \n",
    "    -- Product metrics\n",
    "    COUNT(DISTINCT oi.product_id) as daily_unique_products,\n",
    "    COUNT(DISTINCT p.product_category_name) as daily_categories,\n",
    "    \n",
    "    -- Payment metrics\n",
    "    COUNT(DISTINCT op.payment_type) as payment_methods_used,\n",
    "    AVG(op.payment_installments) as avg_installments,\n",
    "    \n",
    "    -- Review metrics\n",
    "    COUNT(DISTINCT rev.review_id) as daily_reviews,\n",
    "    AVG(rev.review_score) as avg_daily_review_score,\n",
    "    \n",
    "    -- Day of week features\n",
    "    DAYOFWEEK(o.order_purchase_timestamp) as day_of_week,\n",
    "    CASE \n",
    "        WHEN DAYOFWEEK(o.order_purchase_timestamp) IN (1, 7) THEN 1\n",
    "        ELSE 0\n",
    "    END as is_weekend,\n",
    "    \n",
    "    -- Month features\n",
    "    MONTH(o.order_purchase_timestamp) as month,\n",
    "    QUARTER(o.order_purchase_timestamp) as quarter,\n",
    "    \n",
    "    -- Rolling averages (for ML)\n",
    "    AVG(COUNT(DISTINCT o.order_id)) OVER (\n",
    "        ORDER BY DATE(o.order_purchase_timestamp) \n",
    "        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n",
    "    ) as weekly_avg_orders,\n",
    "    \n",
    "    AVG(SUM(oi.price)) OVER (\n",
    "        ORDER BY DATE(o.order_purchase_timestamp) \n",
    "        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n",
    "    ) as weekly_avg_revenue\n",
    "    \n",
    "FROM bronze.orders o\n",
    "JOIN bronze.order_items oi ON o.order_id = oi.order_id\n",
    "LEFT JOIN bronze.products p ON oi.product_id = p.product_id\n",
    "LEFT JOIN bronze.order_payments op ON o.order_id = op.order_id\n",
    "LEFT JOIN bronze.order_reviews rev ON o.order_id = rev.order_id\n",
    "WHERE o.order_purchase_timestamp IS NOT NULL\n",
    "GROUP BY DATE(o.order_purchase_timestamp), \n",
    "         DAYOFWEEK(o.order_purchase_timestamp),\n",
    "         MONTH(o.order_purchase_timestamp),\n",
    "         QUARTER(o.order_purchase_timestamp)\n",
    "ORDER BY order_date\n",
    "\"\"\"\n",
    "\n",
    "# Execute and save\n",
    "time_series_df = spark.sql(time_series_features)\n",
    "time_series_df.write.mode(\"overwrite\").saveAsTable(\"brazil_project.gold.time_series_features\")\n",
    "\n",
    "print(f\"✅ Time-Series Features created: {time_series_df.count():,} days\")\n",
    "print(\"   Features: Daily metrics with rolling averages for forecasting\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ea5ee57-6e99-48bf-a597-aa23c82273e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###4: CREATE ML DATASET FOR CHURN PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc277469-7b49-4b2e-b9ec-5855bd2b0079",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n4️⃣ CREATING ML DATASET FOR CHURN PREDICTION\n✅ ML Dataset created: 98,666 samples\n   Features: 25+ features for churn prediction\n   Label: churn_next_30d (1=will churn, 0=won't churn)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n4️⃣ CREATING ML DATASET FOR CHURN PREDICTION\")\n",
    "\n",
    "# Prepare final ML dataset\n",
    "ml_dataset = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    -- Customer demographics\n",
    "    customer_state,\n",
    "    customer_segment,\n",
    "    value_segment,\n",
    "    \n",
    "    -- Behavioral features\n",
    "    total_orders,\n",
    "    total_spent,\n",
    "    avg_order_value,\n",
    "    unique_categories_purchased,\n",
    "    unique_payment_methods,\n",
    "    avg_installments,\n",
    "    total_reviews,\n",
    "    avg_review_score,\n",
    "    avg_delivery_days,\n",
    "    \n",
    "    -- Time-based features\n",
    "    customer_tenure_days,\n",
    "    days_since_last_purchase,\n",
    "    \n",
    "    -- RFM features\n",
    "    recency_score,\n",
    "    frequency_score,\n",
    "    monetary_score,\n",
    "    rfm_total_score,\n",
    "    \n",
    "    -- Order status\n",
    "    delivered_orders,\n",
    "    canceled_orders,\n",
    "    unavailable_orders,\n",
    "    \n",
    "    -- Geographic context\n",
    "    state_total_customers,\n",
    "    state_avg_spent,\n",
    "    \n",
    "    -- Derived features\n",
    "    estimated_lifetime_value,\n",
    "    \n",
    "    -- Target variable\n",
    "    churn_next_30d as label\n",
    "    \n",
    "FROM gold.ml_customer_features\n",
    "WHERE customer_tenure_days IS NOT NULL\n",
    "  AND total_orders > 0\n",
    "\"\"\")\n",
    "\n",
    "# Save to ML schema\n",
    "ml_dataset.write.mode(\"overwrite\").saveAsTable(\"brazil_project.ml.churn_prediction_dataset\")\n",
    "\n",
    "print(f\"✅ ML Dataset created: {ml_dataset.count():,} samples\")\n",
    "print(\"   Features: 25+ features for churn prediction\")\n",
    "print(\"   Label: churn_next_30d (1=will churn, 0=won't churn)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e5228eb-476c-4ed9-a733-6b0adc1562dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5: OPTIMIZE GOLD TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "385b0778-df21-4e2c-9911-4012839fa1c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n5️⃣ OPTIMIZING GOLD TABLES\n\uD83D\uDD27 Optimizing gold.ml_customer_features...\n   ⚠️ Could not optimize\n\uD83D\uDD27 Optimizing gold.ml_product_features...\n   ⚠️ Could not optimize\n\uD83D\uDD27 Optimizing gold.time_series_features...\n   ⚠️ Could not optimize\n\uD83D\uDD27 Optimizing ml.churn_prediction_dataset...\n   ✅ Optimized\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n5️⃣ OPTIMIZING GOLD TABLES\")\n",
    "\n",
    "# Optimize all gold tables\n",
    "tables_to_optimize = [\n",
    "    \"gold.ml_customer_features\",\n",
    "    \"gold.ml_product_features\", \n",
    "    \"gold.time_series_features\",\n",
    "    \"ml.churn_prediction_dataset\"\n",
    "]\n",
    "\n",
    "for table in tables_to_optimize:\n",
    "    print(f\"\uD83D\uDD27 Optimizing {table}...\")\n",
    "    try:\n",
    "        spark.sql(f\"OPTIMIZE {table} ZORDER BY (customer_state, label)\")\n",
    "        print(f\"   ✅ Optimized\")\n",
    "    except:\n",
    "        print(f\"   ⚠️ Could not optimize\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d93ff7f-781e-4b52-8fe2-dbadc7be1344",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###6: CREATE BUSINESS INSIGHTS (GOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "691c1aee-229d-4610-b4ab-7cc215543c5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n6️⃣ GENERATING BUSINESS INSIGHTS\n\n\uD83D\uDCCA KEY BUSINESS INSIGHTS FROM GOLD LAYER\n======================================================================\n\n\uD83D\uDD0D CHURN ANALYSIS:\n+----------------+---------------+--------------------+------------------+------------------+-----------------------+\n|customer_segment|total_customers|churn_risk_customers|churn_rate_percent|avg_customer_value|avg_days_since_purchase|\n+----------------+---------------+--------------------+------------------+------------------+-----------------------+\n|        Very New|          98666|                   0|              0.00|            137.75|                 2947.7|\n+----------------+---------------+--------------------+------------------+------------------+-----------------------+\n\n\n\uD83D\uDCB0 HIGH-VALUE CUSTOMER SEGMENTS:\n+--------------+--------------+---------+-------------+----------------------+----------------+\n| value_segment|customer_state|customers|total_revenue|avg_spent_per_customer|avg_satisfaction|\n+--------------+--------------+---------+-------------+----------------------+----------------+\n|    High Value|            SP|     4593|   2097052.66|                456.58|            4.13|\n|  Medium Value|            SP|     9524|   1501068.85|                157.61|            4.17|\n|     Low Value|            SP|    12182|   1043625.76|                 85.67|            4.14|\n|    High Value|            RJ|     1649|    797855.61|                483.84|            3.79|\n|    High Value|            MG|     1432|    677604.26|                473.19|            4.09|\n|Very Low Value|            SP|    15076|    561207.78|                 37.23|             4.2|\n|  Medium Value|            RJ|     3399|    541028.01|                159.17|            3.84|\n|  Medium Value|            MG|     2959|    464608.96|                157.02|            4.18|\n|     Low Value|            RJ|     3874|    338414.32|                 87.36|            3.86|\n|    High Value|            RS|      711|    322382.49|                453.42|             4.1|\n+--------------+--------------+---------+-------------+----------------------+----------------+\n\n\n\uD83C\uDFC6 TOP PERFORMING PRODUCT CATEGORIES:\n+---------------------+--------+-----------+-------------+----------+-------------------+\n|product_category_name|products|total_sales|total_revenue|avg_rating|high_demand_percent|\n+---------------------+--------+-----------+-------------+----------+-------------------+\n|         beleza_saude|    2444|       9670|   1258681.34|      4.17|               0.57|\n|   relogios_presentes|    1329|       5991|   1205005.68|      4.14|               0.38|\n|      cama_mesa_banho|    3029|      11115|   1036988.68|      3.84|               0.23|\n|        esporte_lazer|    2867|       8641|    988048.97|      4.11|               0.24|\n| informatica_acess...|    1639|       7827|    911954.32|      3.93|               0.49|\n|     moveis_decoracao|    2657|       8334|    729762.49|      3.88|               0.15|\n|           cool_stuff|     789|       3796|    635290.85|       4.1|               1.01|\n| utilidades_domest...|    2335|       6964|    632248.66|      4.06|               0.13|\n|           automotivo|    1900|       4235|    592720.11|      4.02|               0.32|\n|   ferramentas_jardim|     753|       4347|    485256.46|      4.08|               0.93|\n+---------------------+--------+-----------+-------------+----------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n6️⃣ GENERATING BUSINESS INSIGHTS\")\n",
    "\n",
    "print(\"\\n\uD83D\uDCCA KEY BUSINESS INSIGHTS FROM GOLD LAYER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Insight 1: Churn Analysis\n",
    "print(\"\\n\uD83D\uDD0D CHURN ANALYSIS:\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        customer_segment,\n",
    "        COUNT(*) as total_customers,\n",
    "        SUM(CASE WHEN label = 1 THEN 1 ELSE 0 END) as churn_risk_customers,\n",
    "        ROUND(SUM(CASE WHEN label = 1 THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2) as churn_rate_percent,\n",
    "        ROUND(AVG(total_spent), 2) as avg_customer_value,\n",
    "        ROUND(AVG(days_since_last_purchase), 1) as avg_days_since_purchase\n",
    "    FROM ml.churn_prediction_dataset\n",
    "    GROUP BY customer_segment\n",
    "    ORDER BY churn_rate_percent DESC\n",
    "\"\"\").show()\n",
    "\n",
    "# Insight 2: High-Value Customer Segments\n",
    "print(\"\\n\uD83D\uDCB0 HIGH-VALUE CUSTOMER SEGMENTS:\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        value_segment,\n",
    "        customer_state,\n",
    "        COUNT(*) as customers,\n",
    "        ROUND(SUM(total_spent), 2) as total_revenue,\n",
    "        ROUND(AVG(total_spent), 2) as avg_spent_per_customer,\n",
    "        ROUND(AVG(avg_review_score), 2) as avg_satisfaction\n",
    "    FROM gold.ml_customer_features\n",
    "    WHERE total_spent > 0\n",
    "    GROUP BY value_segment, customer_state\n",
    "    ORDER BY total_revenue DESC\n",
    "    LIMIT 10\n",
    "\"\"\").show()\n",
    "\n",
    "# Insight 3: Product Performance\n",
    "print(\"\\n\uD83C\uDFC6 TOP PERFORMING PRODUCT CATEGORIES:\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        product_category_name,\n",
    "        COUNT(DISTINCT product_id) as products,\n",
    "        SUM(total_items_sold) as total_sales,\n",
    "        ROUND(SUM(total_revenue), 2) as total_revenue,\n",
    "        ROUND(AVG(avg_review_score), 2) as avg_rating,\n",
    "        ROUND(SUM(CASE WHEN high_demand_product = 1 THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2) as high_demand_percent\n",
    "    FROM gold.ml_product_features\n",
    "    WHERE product_category_name IS NOT NULL\n",
    "    GROUP BY product_category_name\n",
    "    ORDER BY total_revenue DESC\n",
    "    LIMIT 10\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b29da891-5491-407e-a559-01dcfae008c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83C\uDFAF ARCHITECTURE DIAGRAM\n============================================================\n\n\uD83C\uDFD7️ MEDALLION ARCHITECTURE IMPLEMENTED:\n\n    ┌─────────────────────────────────────┐\n    │        BRONZE LAYER (Raw)           │\n    │  ┌─────────────────────────────┐    │\n    │  │ • 8 CSV files from Kaggle   │    │\n    │  │ • customers (99K rows)      │    │\n    │  │ • orders (99K rows)         │    │\n    │  │ • order_items (112K rows)   │    │\n    │  │ • products (32K rows)       │    │\n    │  │ • + 4 more tables           │    │\n    │  └─────────────────────────────┘    │\n    │               ↓                     │\n    │        Clean & Validate             │\n    └─────────────────────────────────────┘\n                     ↓\n    ┌─────────────────────────────────────┐\n    │        SILVER LAYER (Cleaned)       │\n    │  ┌─────────────────────────────┐    │\n    │  │ • customer_360_simple       │    │\n    │  │ • RFM Features:             │    │\n    │  │   - Recency Score (1-5)     │    │\n    │  │   - Frequency Score (1-5)   │    │\n    │  │   - Monetary Score (1-5)    │    │\n    │  │ • Churn Flag: churned_90d   │    │\n    │  └─────────────────────────────┘    │\n    │               ↓                     │\n    │        Feature Engineering          │\n    └─────────────────────────────────────┘\n                     ↓\n    ┌─────────────────────────────────────┐\n    │        GOLD LAYER (ML-ready)        │\n    │  ┌─────────────────────────────┐    │\n    │  │ • ml_customer_features      │    │\n    │  │   - 25+ engineered features │    │\n    │  │   - Customer segments       │    │\n    │  │   - Value segments          │    │\n    │  │ • ml_product_features       │    │\n    │  │ • time_series_features      │    │\n    │  │ • churn_prediction_dataset  │    │\n    │  │   (98,666 samples)          │    │\n    │  └─────────────────────────────┘    │\n    │               ↓                     │\n    │        Ready for ML Training        │\n    └─────────────────────────────────────┘\n\n\uD83C\uDFAF NEXT: Day 4 → Machine Learning & Predictions\n\n\n\uD83D\uDCCA SCHEMA STRUCTURE:\n========================================\nbrazil_project (Catalog)\n├── bronze/              # Raw ingested data\n│   ├── customers\n│   ├── orders\n│   ├── order_items\n│   └── ... (5 more)\n├── silver/              # Cleaned, joined\n│   └── customer_360_simple\n├── gold/                # Business & ML ready\n│   ├── ml_customer_features\n│   ├── ml_product_features\n│   └── time_series_features\n└── ml/                  # Machine Learning\n    ├── churn_prediction_dataset\n    └── customer_churn_predictions (Day 4 output)\n"
     ]
    }
   ],
   "source": [
    "print(\"\uD83C\uDFAF ARCHITECTURE DIAGRAM\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "\uD83C\uDFD7️ MEDALLION ARCHITECTURE IMPLEMENTED:\n",
    "\n",
    "    ┌─────────────────────────────────────┐\n",
    "    │        BRONZE LAYER (Raw)           │\n",
    "    │  ┌─────────────────────────────┐    │\n",
    "    │  │ • 8 CSV files from Kaggle   │    │\n",
    "    │  │ • customers (99K rows)      │    │\n",
    "    │  │ • orders (99K rows)         │    │\n",
    "    │  │ • order_items (112K rows)   │    │\n",
    "    │  │ • products (32K rows)       │    │\n",
    "    │  │ • + 4 more tables           │    │\n",
    "    │  └─────────────────────────────┘    │\n",
    "    │               ↓                     │\n",
    "    │        Clean & Validate             │\n",
    "    └─────────────────────────────────────┘\n",
    "                     ↓\n",
    "    ┌─────────────────────────────────────┐\n",
    "    │        SILVER LAYER (Cleaned)       │\n",
    "    │  ┌─────────────────────────────┐    │\n",
    "    │  │ • customer_360_simple       │    │\n",
    "    │  │ • RFM Features:             │    │\n",
    "    │  │   - Recency Score (1-5)     │    │\n",
    "    │  │   - Frequency Score (1-5)   │    │\n",
    "    │  │   - Monetary Score (1-5)    │    │\n",
    "    │  │ • Churn Flag: churned_90d   │    │\n",
    "    │  └─────────────────────────────┘    │\n",
    "    │               ↓                     │\n",
    "    │        Feature Engineering          │\n",
    "    └─────────────────────────────────────┘\n",
    "                     ↓\n",
    "    ┌─────────────────────────────────────┐\n",
    "    │        GOLD LAYER (ML-ready)        │\n",
    "    │  ┌─────────────────────────────┐    │\n",
    "    │  │ • ml_customer_features      │    │\n",
    "    │  │   - 25+ engineered features │    │\n",
    "    │  │   - Customer segments       │    │\n",
    "    │  │   - Value segments          │    │\n",
    "    │  │ • ml_product_features       │    │\n",
    "    │  │ • time_series_features      │    │\n",
    "    │  │ • churn_prediction_dataset  │    │\n",
    "    │  │   (98,666 samples)          │    │\n",
    "    │  └─────────────────────────────┘    │\n",
    "    │               ↓                     │\n",
    "    │        Ready for ML Training        │\n",
    "    └─────────────────────────────────────┘\n",
    "\n",
    "\uD83C\uDFAF NEXT: Day 4 → Machine Learning & Predictions\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\uD83D\uDCCA SCHEMA STRUCTURE:\")\n",
    "print(\"=\"*40)\n",
    "print(\"brazil_project (Catalog)\")\n",
    "print(\"├── bronze/              # Raw ingested data\")\n",
    "print(\"│   ├── customers\")\n",
    "print(\"│   ├── orders\")\n",
    "print(\"│   ├── order_items\")\n",
    "print(\"│   └── ... (5 more)\")\n",
    "print(\"├── silver/              # Cleaned, joined\")\n",
    "print(\"│   └── customer_360_simple\")\n",
    "print(\"├── gold/                # Business & ML ready\")\n",
    "print(\"│   ├── ml_customer_features\")\n",
    "print(\"│   ├── ml_product_features\")\n",
    "print(\"│   └── time_series_features\")\n",
    "print(\"└── ml/                  # Machine Learning\")\n",
    "print(\"    ├── churn_prediction_dataset\")\n",
    "print(\"    └── customer_churn_predictions (Day 4 output)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0a3f0df-d5e4-47b2-9b93-bd975c9c89bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCC1 ACTUAL DATABRICKS STRUCTURE\n==================================================\n\n1️⃣ CATALOGS:\n   ✅ brazil_project (Our project catalog)\n\n2️⃣ SCHEMAS in brazil_project:\n   • bronze\n   • data\n   • default\n   • gold\n   • information_schema\n   • ml\n   • silver\n\n3️⃣ TABLES in Each Schema:\n\n   \uD83D\uDCC2 BRONZE:\n      └ customers\n      └ geolocation\n      └ order_items\n      └ order_payments\n      └ order_reviews\n      └ orders\n      └ products\n      └ sellers\n\n   \uD83D\uDCC2 SILVER:\n      └ customer_360_simple\n\n   \uD83D\uDCC2 GOLD:\n      └ ml_customer_features\n      └ ml_product_features\n      └ time_series_features\n\n   \uD83D\uDCC2 ML:\n      └ churn_prediction_dataset\n      └ customer_churn_predictions\n      └ customer_predictions\n"
     ]
    }
   ],
   "source": [
    "print(\"\uD83D\uDCC1 ACTUAL DATABRICKS STRUCTURE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\n1️⃣ CATALOGS:\")\n",
    "catalogs = spark.sql(\"SHOW CATALOGS\").collect()\n",
    "for cat in catalogs:\n",
    "    if cat.catalog == \"brazil_project\":\n",
    "        print(f\"   ✅ {cat.catalog} (Our project catalog)\")\n",
    "\n",
    "print(\"\\n2️⃣ SCHEMAS in brazil_project:\")\n",
    "spark.sql(\"USE CATALOG brazil_project\")\n",
    "schemas = spark.sql(\"SHOW SCHEMAS\").collect()\n",
    "for schema in schemas:\n",
    "    print(f\"   • {schema.databaseName}\")\n",
    "\n",
    "print(\"\\n3️⃣ TABLES in Each Schema:\")\n",
    "for schema in ['bronze', 'silver', 'gold', 'ml']:\n",
    "    try:\n",
    "        print(f\"\\n   \uD83D\uDCC2 {schema.upper()}:\")\n",
    "        tables = spark.sql(f\"SHOW TABLES IN {schema}\").collect()\n",
    "        for table in tables:\n",
    "            print(f\"      └ {table.tableName}\")\n",
    "    except:\n",
    "        print(f\"   ⚠️  Could not access {schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5350c87-8f7f-4969-b553-03ac00c982e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "part 3",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}